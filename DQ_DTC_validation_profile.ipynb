{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet will test an already trained DQ-DTC agent on the validation profile:\n",
    "\n",
    "<img src=\"Figures/Validation_Profile.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LeakyReLU, ELU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory, EpisodeParameterMemory\n",
    "from CustomKerasRL2Callbacks_torqueCtrl import StoreEpisodeLogger\n",
    "from gym.wrappers import FlattenObservation\n",
    "from gym.core import Wrapper\n",
    "from gym.spaces import Box, Tuple\n",
    "import sys, os\n",
    "import h5py\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import gym_electric_motor as gem\n",
    "from gym_electric_motor.reward_functions import WeightedSumOfErrors\n",
    "from gym_electric_motor.physical_systems import ConstantSpeedLoad, ExternalSpeedLoad\n",
    "from gym_electric_motor.reference_generators import WienerProcessReferenceGenerator, ConstReferenceGenerator, \\\n",
    "    MultipleReferenceGenerator, StepReferenceGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_profile_speed(t):\n",
    "    \"\"\"\n",
    "    This function defines the speed profile of the validation episode.\n",
    "    \"\"\"\n",
    "    lim = 12000 * 2 * np.pi / 60\n",
    "\n",
    "    niveau0 = 00\n",
    "    niveau1 = 0.15 * lim\n",
    "    niveau2 = 0.5 * lim\n",
    "\n",
    "    if t <= 0.05:\n",
    "        omega = niveau0\n",
    "    elif t <= 0.20:\n",
    "        omega = (t - 0.05) * (niveau1 - niveau0) / 0.15 + niveau0\n",
    "    elif t <= 1.3:\n",
    "        omega = niveau1\n",
    "    elif t <= 1.45:\n",
    "        omega = (t - 1.3) * -2 * niveau1 / 0.15 + niveau1\n",
    "    elif t <= 2.55:\n",
    "        omega = - niveau1\n",
    "    elif t <= 2.7:\n",
    "        omega = (t - 2.55) * (niveau1 + niveau2) / 0.15 - niveau1\n",
    "    elif t <= 3.8:\n",
    "        omega = niveau2\n",
    "    elif t <= 3.95:\n",
    "        omega = (t - 3.8) * -2 * niveau2 / 0.15 + niveau2\n",
    "    elif t <= 5.05:\n",
    "        omega = - niveau2\n",
    "    elif t <= 5.2:\n",
    "        omega = (t - 5.05) * (niveau0 + niveau2) / 0.15 - niveau2\n",
    "    else:\n",
    "        omega = niveau0\n",
    "\n",
    "    return omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformObservationWrapper(Wrapper):\n",
    "    \"\"\"\n",
    "    The following environment considers the dead time in the real-world motor control systems.\n",
    "    The real-world system changes its state, while the agent calculates the next action based on a previously measured\n",
    "    observation. Therefore, for the agent it seems as if the applied action effects the state one step delayed.\n",
    "    (with a dead time of one time-step)\n",
    "\n",
    "    For complete observability of the system at each time-step we append the last played action of the agent to the\n",
    "    observation, because this action will be the one that is active in the next step.\n",
    "    \"\"\"\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(environment)\n",
    "        # reduced observation space [w_me, i_d, i_q, u_d, u_q, cos(eps), sin(eps), T_ref] (all normalized)\n",
    "        self.observation_space = Tuple((Box(\n",
    "            np.concatenate(([environment.observation_space[0].low[0]],\n",
    "                            environment.observation_space[0].low[5:7],\n",
    "                            environment.observation_space[0].low[10:12],\n",
    "                            [-1, -1],\n",
    "                            [-1])),\n",
    "            np.concatenate(([environment.observation_space[0].high[0]],\n",
    "                            environment.observation_space[0].high[5:7],\n",
    "                            environment.observation_space[0].high[10:12],\n",
    "                            [+1, +1],\n",
    "                            [+1])),\n",
    "        ), environment.observation_space[1]))\n",
    "\n",
    "        self.subactions = -np.power(-1, self.env.physical_system._converter._subactions)\n",
    "        \n",
    "        # gamma = 0 is assumed for calculating the return G in the test case\n",
    "        self.gamma = 0\n",
    "        self.test = True\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        (state, ref), rew, term, info = self.env.step(action)\n",
    "\n",
    "        self._obs_logger = np.concatenate((state, ref))\n",
    "\n",
    "        eps = state[12] * np.pi\n",
    "        angle_scale = 0.1\n",
    "        angles = [angle_scale * np.cos(eps), angle_scale * np.sin(eps)]\n",
    "\n",
    "        u_abc = self.subactions[action]\n",
    "        u_dq = self.env.physical_system.abc_to_dq_space(u_abc, epsilon_el=eps)\n",
    "        now_requested_voltage = u_dq\n",
    "        \n",
    "        i_d = state[5]\n",
    "        i_q = state[6]\n",
    "        T = state[1]\n",
    "        T_ref = ref[0]\n",
    "\n",
    "        current_total = np.sqrt(i_d ** 2 + i_q ** 2)\n",
    "\n",
    "        # building the custom observation vector\n",
    "        observable_state = np.concatenate(([state[0]],\n",
    "                                           state[5:7],\n",
    "                                           now_requested_voltage,\n",
    "                                           angles,\n",
    "                                           [2 * current_total - 1]))\n",
    "\n",
    "        # as this script is only for testing there is no benefit in defining the reward\n",
    "        reward = None\n",
    "\n",
    "        return (observable_state, ref), rew, term, info\n",
    "    \n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        state, ref = self.env.reset()\n",
    "\n",
    "        self._obs_logger = np.concatenate((state, ref))\n",
    "\n",
    "        eps = state[12] * np.pi\n",
    "        angle_scale = 0.1\n",
    "        angles = [angle_scale * np.cos(eps), angle_scale * np.sin(eps)]\n",
    "        torque_error = [(ref[0] - state[1]) / 2]\n",
    "\n",
    "        u_abc = self.subactions[0]\n",
    "        u_dq = self.env.physical_system.abc_to_dq_space(u_abc, epsilon_el=eps)\n",
    "        now_requested_voltage = u_dq  # reduced observation\n",
    "\n",
    "        i_d = state[5]\n",
    "        i_q = state[6]\n",
    "\n",
    "        current_total = np.sqrt(i_d ** 2 + i_q ** 2)\n",
    "\n",
    "\n",
    "        observable_state = np.concatenate(([state[0]], \n",
    "                                           state[5:7], \n",
    "                                           now_requested_voltage, \n",
    "                                           angles, \n",
    "                                           [2 * current_total - 1]))  # reduced observation\n",
    "\n",
    "        return (observable_state, ref)\n",
    "\n",
    "torque_ref_generator = ConstReferenceGenerator(reference_state='torque', reference_value=np.random.uniform(-1, 1))\n",
    "\n",
    "motor_parameter = dict(p=3,            # [p] = 1, nb of pole pairs\n",
    "                       r_s=17.932e-3,  # [r_s] = Ohm, stator resistance\n",
    "                       l_d=0.37e-3,    # [l_d] = H, d-axis inductance\n",
    "                       l_q=1.2e-3,     # [l_q] = H, q-axis inductance\n",
    "                       psi_p=65.65e-3, # [psi_p] = Vs, magnetic flux of the permanent magnet\n",
    "                       )  # BRUSA\n",
    "\n",
    "u_sup = 350\n",
    "nominal_values=dict(omega=12000 * 2 * np.pi / 60,\n",
    "                    i=240,\n",
    "                    u=u_sup\n",
    "                    )\n",
    "\n",
    "limit_values=nominal_values.copy()\n",
    "limit_values[\"i\"] = 270\n",
    "limit_values[\"torque\"] = 200\n",
    "\n",
    "def test_agent(param_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    this function is used to perform one validation episode with predefined network weights\n",
    "    although these weights were saved in beforehand one still needs to initialize a network of the\n",
    "    corresponding form to load the weights into\n",
    "    \"\"\"\n",
    "\n",
    "    # unpack the parameters\n",
    "    subfolder_name = param_dict[\"subfolder_name\"]\n",
    "\n",
    "    layers = param_dict[\"layers\"]\n",
    "    neurons = param_dict[\"neurons\"]\n",
    "    activation_fcn =  param_dict[\"activation_fcn\"]\n",
    "    activation_fcn_parameter = param_dict[\"activation_fcn_parameter\"]\n",
    "   \n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "    Path(subfolder_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # build the environment for the validation profile\n",
    "    env = gem.make(\"Finite-TC-PMSM-v0\",\n",
    "                   motor = dict(\n",
    "                       motor_parameter=motor_parameter,\n",
    "                       limit_values=limit_values,\n",
    "                       nominal_values=nominal_values\n",
    "                   ),\n",
    "                   supply=dict(u_nominal=u_sup),\n",
    "                   load=ExternalSpeedLoad(speed_profile=test_profile_speed, # here, the speed profile is implemented\n",
    "                                          tau=50e-6),\n",
    "                   tau=50e-6,\n",
    "                   reward_function=WeightedSumOfErrors(reward_weights={'torque': 1}, \n",
    "                                                              gamma=0),\n",
    "                   reference_generator=torque_ref_generator,\n",
    "                   ode_solver='scipy.solve_ivp'\n",
    "                   )\n",
    "\n",
    "    (x, r) = env.reset()\n",
    "    tau=env._physical_system.tau\n",
    "    limits = env.physical_system.limits\n",
    "\n",
    "    # wrap the environment for proper \n",
    "    env = FlattenObservation(TransformObservationWrapper(env))\n",
    "\n",
    "    # define the network, has to be the same as in the training profile\n",
    "    # select special procedure for parameterized activations\n",
    "    if activation_fcn == \"leaky_relu\" or activation_fcn == \"elu\":\n",
    "        dense_activation_fcn = 'linear'\n",
    "    else:\n",
    "        dense_activation_fcn = activation_fcn\n",
    "    \n",
    "    \n",
    "    nb_actions = env.action_space.n\n",
    "    window_length = 1\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(window_length,) + env.observation_space.shape))\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(neurons, activation=dense_activation_fcn))\n",
    "        if activation_fcn == 'leaky_relu':\n",
    "            model.add(LeakyReLU(alpha=activation_fcn_parameter))\n",
    "        elif activation_fcn == 'elu':\n",
    "            model.add(ELU(alpha=activation_fcn_parameter))\n",
    "    model.add(Dense(nb_actions,\n",
    "                    activation='linear'\n",
    "                    ))\n",
    "\n",
    "    # memory will not be used in testing episodes, probably one could avoid initializing it\n",
    "    memory = SequentialMemory(limit=0, window_length=window_length)\n",
    "\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(eps=0),\n",
    "                                  attr='eps',\n",
    "                                  value_max=0,\n",
    "                                  value_min=0,\n",
    "                                  value_test=0, # this is the epsilon used for testing episodes, 0 means deterministic operation\n",
    "                                  nb_steps=0)\n",
    "\n",
    "    # define the agent\n",
    "    agent = DQNAgent(model=model,\n",
    "                     nb_actions=nb_actions,\n",
    "                     gamma=0,\n",
    "                     batch_size=4,\n",
    "                     memory=memory,\n",
    "                     memory_interval=1,\n",
    "                     policy=policy,\n",
    "                     train_interval=1,\n",
    "                     target_model_update=0,\n",
    "                     enable_double_dqn=False)\n",
    "\n",
    "    # compile the agent and load the weights that were learned during training\n",
    "    agent.compile(Adam(lr=0), metrics=['mse'])\n",
    "    agent.load_weights(filepath=subfolder_name + \"/\" + \"weights.hdf5\")\n",
    "\n",
    "    # define the callback for the testing routine\n",
    "    logger = StoreEpisodeLogger(folder_name=subfolder_name,\n",
    "                                file_name=\"DQ_DTC_validation_episode\",\n",
    "                                tau=tau, limits=limits, training=True,\n",
    "                                lr_max=0, lr_min=0,\n",
    "                                nb_steps_start=0,\n",
    "                                nb_steps_reduction=0,\n",
    "                                speed_generator=None,\n",
    "                                create_eps_logs=True,\n",
    "                                test=True)\n",
    "    callbacks = [logger]\n",
    "\n",
    "    # perform one testing episode, the length of the episode \"nb_max_episode_steps\" was adjusted to the speed / torque profile\n",
    "    history = agent.test(env,\n",
    "                        nb_episodes=1,\n",
    "                        action_repetition=1,\n",
    "                        verbose=0,\n",
    "                        visualize=False,\n",
    "                        nb_max_episode_steps=130000,\n",
    "                        callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameterize the agent\n",
    "# the \"subfolder_name\" is the directory where the network weights \"weights.hdf5\" will be taken from\n",
    "\n",
    "subfolder_name = \"Exemplary_Weights\"\n",
    "\n",
    "# this short block will read out the weights dimensions to set the correct network geometry\n",
    "# only activation fcn and activation fcn parameter will need to be set manually\n",
    "with h5py.File(subfolder_name + \"/weights.hdf5\", \"r\") as f:\n",
    "    dense = np.copy(f[\"dense\"][\"dense\"][\"kernel:0\"])\n",
    "    nb_neurons = np.shape(dense)[1]\n",
    "    keys = list(f.keys())\n",
    "nb_layers = -1\n",
    "for key in keys:\n",
    "    if \"dense\" in key:\n",
    "        nb_layers += 1\n",
    "\n",
    "param_dict = {\"subfolder_name\": subfolder_name,\n",
    "              \"layers\": nb_layers,\n",
    "              \"neurons\": nb_neurons,\n",
    "              \"activation_fcn\": \"leaky_relu\",\n",
    "              \"activation_fcn_parameter\": 0.3425,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will run the test episode\n",
    "# run time depends on the CPU speed, might take more than 20 minutes\n",
    "# please stay patient although no progress bar is displayed\n",
    "test_agent(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plot_TimeDomain_torqueCtrl import plot_episode\n",
    "\n",
    "# this function will save a pdf of the validation episode to the \"Plots\" folder\n",
    "# a \"Plots\" folder will be created if there is none\n",
    "plot_episode(training_folder = \"Exemplary_Weights\",\n",
    "             episode_number = 0,\n",
    "             episode_type = \"DQ_DTC_validation_episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DQDTC_req]",
   "language": "python",
   "name": "conda-env-DQDTC_req-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
